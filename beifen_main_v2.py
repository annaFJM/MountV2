import requests
import json
import os
import sys
import logging
# from volcenginesdkarkruntime import Ark
from openai import OpenAI
from datetime import datetime
import numpy as np 
from numpy.linalg import norm 
# import torch 
# from transformers import AutoTokenizer, AutoModel
sys.path.append(os.getcwd())
from config import (
    NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD,
    DATA_FILE_PATH, 
    # DEEPSEEK_API_KEY , DEEPSEEK_BASE_URL,
    # VOLCANO_API_KEY, VOLCANO_REGION,
    RESULT_DIR, RESULT_FILE_PREFIX
)
from neo4j_connector import Neo4jConnector

log_dir = "/home/thl/2025Fall/LLM_Mount_KG/log"
os.makedirs(log_dir, exist_ok=True)
log_timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
log_filepath = os.path.join(log_dir, f"{log_timestamp}.log")
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filepath, encoding='utf-8'),
        logging.StreamHandler()  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)

# æ•°æ®åº“æ¥å£åˆå§‹åŒ–
neo4j = Neo4jConnector(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)

client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

'''
# --- 1. åŠ è½½è¿è¡Œæ—¶Embeddingæ¨¡å‹ --- # 
RUNTIME_EMBED_MODEL_PATH = "/home/thl/models/Qwen3-4B-clustering_1078/checkpoint-936" 
RUNTIME_EMBED_DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
RUNTIME_EMBED_TOKENIZER = None
RUNTIME_EMBED_MODEL = None

try:
    logging.info(f"--- æ­£åœ¨åŠ è½½è¿è¡Œæ—¶Embeddingæ¨¡å‹åˆ° {RUNTIME_EMBED_DEVICE} ---")
    RUNTIME_EMBED_TOKENIZER = AutoTokenizer.from_pretrained(RUNTIME_EMBED_MODEL_PATH)
    RUNTIME_EMBED_MODEL = AutoModel.from_pretrained(
        RUNTIME_EMBED_MODEL_PATH, 
        torch_dtype="auto"
    ).to(RUNTIME_EMBED_DEVICE).eval()
    logging.info(f"âœ… æˆåŠŸåŠ è½½ç”¨äºè¿è¡Œæ—¶æ¨ç†çš„Embeddingæ¨¡å‹ã€‚")
except Exception as e:
    logging.info(f"âš ï¸ è­¦å‘Šï¼šæœªèƒ½åŠ è½½è¿è¡Œæ—¶Embeddingæ¨¡å‹: {e}")
    logging.info("     recall_top5_materials åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")
'''
# --- 2. åŠ è½½é¢„è®¡ç®—çš„å‘é‡åº“ --- # 
# EMBEDDINGS_DB_PATH = "/home/thl/2025Fall/LLM_Mount_KG/embedding/data/material_embeddings.npy"
# EMBEDDINGS_METADATA_PATH = "/home/thl/2025Fall/LLM_Mount_KG/embedding/data/material_metadata.json"

# æµ‹è¯•ç”¨
# EMBEDDINGS_DB_PATH = "/home/thl/2025Fall/LLM_Mount_KG/test/data/material_embeddings.npy"
# EMBEDDINGS_METADATA_PATH = "/home/thl/2025Fall/LLM_Mount_KG/test/data/material_metadata.json"
# åŠ è½½ API ç”Ÿæˆçš„å‘é‡åº“
EMBEDDINGS_DB_PATH = "/home/thl/2025Fall/LLM_Mount_KG/test/data/material_embeddings_qwenAPI.npy"
EMBEDDINGS_METADATA_PATH = "/home/thl/2025Fall/LLM_Mount_KG/test/data/material_metadata_qwenAPI.json"
MATERIAL_EMBEDDINGS = None
MATERIAL_METADATA = []
MATERIAL_ID_TO_METADATA = {} # ç”¨äºå¿«é€ŸæŸ¥æ‰¾

try:
    MATERIAL_EMBEDDINGS = np.load(EMBEDDINGS_DB_PATH)
    with open(EMBEDDINGS_METADATA_PATH, 'r', encoding='utf-8') as f:
        MATERIAL_METADATA = json.load(f)
        # åˆ›å»ºä¸€ä¸ª ID -> å…ƒæ•°æ® çš„æ˜ å°„ï¼Œæ–¹ä¾¿ä½¿ç”¨
        MATERIAL_ID_TO_METADATA = {item['identity']: item for item in MATERIAL_METADATA}
        
    logging.info(f"âœ… æˆåŠŸåŠ è½½ {len(MATERIAL_METADATA)} æ¡é¢„è®¡ç®—çš„Materialå‘é‡ã€‚")
    print(f"ğŸ” ç¤ºä¾‹key: {list(MATERIAL_ID_TO_METADATA.keys())[:3]}")  # çœ‹çœ‹keyæ˜¯ä»€ä¹ˆæ ¼å¼
except Exception as e:
    logging.info(f"âš ï¸ è­¦å‘Šï¼šæœªèƒ½åŠ è½½é¢„è®¡ç®—çš„Materialå‘é‡: {e}")
    logging.info(f"     è·¯å¾„: {EMBEDDINGS_DB_PATH}, {EMBEDDINGS_METADATA_PATH}")
    logging.info("     recall_top5_materials åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")

def get_include_outbound(id):
    # è·å–æ‰€æœ‰includeå‡ºè¾¹
    outbound_ids, outbound_names, outbound_labels = neo4j.get_outbound_by_id(id, "include")
    result_list = []
    # è¡¥å……includeå‡ºè¾¹èŠ‚ç‚¹çš„ä¿¡æ¯
    for i in range(len(outbound_ids)):
        _, extra_out_names, __ = neo4j.get_outbound_by_id(outbound_ids[i],"include")
        _, extra_in_names, __ = neo4j.get_inbound_by_id(outbound_ids[i],"isBelongTo")
        info = f"- é€‰é¡¹{chr(ord('A')+i)}: {outbound_names[i]},idä¸º{outbound_ids[i]},èŠ‚ç‚¹å±æ€§ä¸º{outbound_labels[i]}"
        if len(extra_out_names) > 0:
            info += "è¯¥ä¸‹æ¸¸èŠ‚ç‚¹ä»£è¡¨æ€§çš„includeå‡ºè¾¹æœ‰ï¼š"
            count = 0
            for j in range(len(extra_out_names)):
                if count == 3:
                    break
                info += f"{extra_out_names[j]},"
                count += 1
        else:
            info += "è¯¥ä¸‹æ¸¸èŠ‚ç‚¹æ²¡æœ‰includeå‡ºè¾¹ã€‚"
        if len(extra_in_names) > 0:
            info += "è¯¥ä¸‹æ¸¸èŠ‚ç‚¹ä»£è¡¨æ€§çš„isBelongToå…¥è¾¹æœ‰ï¼š"
            count = 0
            for j in range(len(extra_in_names)):
                if count == 3:
                    break
                info += f"{extra_in_names[j]},"
                count += 1
        else:
            info += "è¯¥ä¸‹æ¸¸èŠ‚ç‚¹æ²¡æœ‰isBelongToå…¥è¾¹ã€‚"
        result_list.append(info)
        # logging.info(info)

    return "\n".join(result_list)

def get_isbelongto_inbound(inbound_ids, inbound_names, inbound_labels):
    # è¿™ä¸ªå‡½æ•°ç°åœ¨æ˜¯ä¸€ä¸ªæ ¼å¼åŒ–å·¥å…·
    # å®ƒåªå¤„ç†ä¼ å…¥çš„æ•°æ®ï¼Œåªå¤„ç†å‰5æ¡
    result_list = []
    
    # åªè¿­ä»£å‰5ä¸ªï¼Œå³ä½¿ä¼ å…¥äº†æ›´å¤š
    for i in range(min(len(inbound_ids), 5)):
        _, extra_out_names, __ = neo4j.get_outbound_by_id(inbound_ids[i], "include")
        # BUG ä¿®å¤ï¼šè¿™é‡Œåº”è¯¥æ˜¯ get_inbound_by_id
        _, extra_in_names, __ = neo4j.get_inbound_by_id(inbound_ids[i], "isBelongTo") 
        info = f"- é€‰é¡¹{chr(ord('A')+i)}: {inbound_names[i]},idä¸º{inbound_ids[i]},èŠ‚ç‚¹å±æ€§ä¸º{inbound_labels[i]}"
        if len(extra_out_names) > 0:
            info += "è¯¥ä¸‹æ¸¸èŠ‚ç‚¹ä»£è¡¨æ€§çš„includeå‡ºè¾¹æœ‰ï¼š"
            count = 0
            for j in range(len(extra_out_names)):
                if count == 3:
                    break
                info += f"{extra_out_names[j]},"
                count += 1
        else:
            info += "è¯¥ä¸‹æ¸¸èŠ‚ç‚¹æ²¡æœ‰includeå‡ºè¾¹ã€‚"
        if len(extra_in_names) > 0:
            info += "è¯¥ä¸‹æ¸¸èŠ‚ç‚¹ä»£è¡¨æ€§çš„isBelongToå…¥è¾¹æœ‰ï¼š"
            count = 0
            for j in range(len(extra_in_names)):
                if count == 3:
                    break
                info += f"{extra_in_names[j]},"
                count += 1
        else:
            info += "è¯¥ä¸‹æ¸¸èŠ‚ç‚¹æ²¡æœ‰isBelongToå…¥è¾¹ã€‚"
        result_list.append(info)
    
    return "\n".join(result_list)

# åŸå‡½æ•°
'''
def get_embedding_for_data(data_item):
    """
    (è¾…åŠ©å‡½æ•°)
    ä¸ºä¼ å…¥çš„å•ä¸ªææ–™æ•°æ®ï¼ˆæ–°æ•°æ®ï¼‰ç”Ÿæˆembeddingã€‚
    """
    if not RUNTIME_EMBED_MODEL or not RUNTIME_EMBED_TOKENIZER:
        logging.info("âŒ è¿è¡Œæ—¶Embeddingæ¨¡å‹æœªåŠ è½½ã€‚")
        return None
    
    # æ‰å¹³åŒ– (æ¥è‡ª neo4j_connector.py)
    def flatten_dict(data_dict, parent_key='', separator='_'):
        items = []
        for key, value in data_dict.items():
            new_key = f"{parent_key}{separator}{key}" if parent_key else key
            if isinstance(value, dict):
                items.extend(flatten_dict(value, new_key, separator=separator).items())
            else:
                items.append((new_key, value))
        return dict(items)

    # å°†data_itemï¼ˆå­—å…¸ï¼‰è½¬æ¢ä¸ºç”¨äºembeddingçš„å­—ç¬¦ä¸²
    # è¿™ä¸€æ­¥çš„æ ¼å¼å¿…é¡»ä¸ generate_material_embeddings.py ä¸­çš„ format_data_for_embedding ä¸€è‡´ï¼
    
    properties_to_embed = data_item.get('data', data_item)
    
    # æ‰å¹³åŒ–å¹¶ç§»é™¤å…ƒæ•°æ®
    flat_properties = flatten_dict(properties_to_embed)
    flat_properties.pop('_id', None) 
    flat_properties.pop('_meta_id', None)
    flat_properties.pop('_tid', None)
    
    # MGE18_æ ‡é¢˜ å¯èƒ½æ˜¯æœ€å¥½çš„ "name" æ›¿ä»£å“
    material_name = flat_properties.pop("MGE18_æ ‡é¢˜", "æœªçŸ¥ç‰Œå·")
    
    props_str = ", ".join([f"{k}: {v}" for k, v in flat_properties.items()])
    
    # *** ç¡®ä¿è¿™ä¸ªæ ¼å¼ä¸ç¦»çº¿è„šæœ¬å®Œå…¨ä¸€è‡´ ***
    text = f"ææ–™åç§°: {material_name}, ææ–™å±æ€§: {props_str}"
    
    with torch.no_grad():
        inputs = RUNTIME_EMBED_TOKENIZER(text, return_tensors="pt", padding=True, truncation=True, max_length=512).to(RUNTIME_EMBED_DEVICE)
        outputs = RUNTIME_EMBED_MODEL(**inputs)
        last_hidden_state = outputs.last_hidden_state
        # ä½¿ç”¨ mean pooling
        embedding = last_hidden_state.mean(dim=1).squeeze()
    
    return embedding.cpu().numpy()
'''
'''
# æµ‹è¯•ç”¨

def get_embedding_for_data(data_item):
    """
    (è¾…åŠ©å‡½æ•°)
    ä¸ºä¼ å…¥çš„å•ä¸ªææ–™æ•°æ®ï¼ˆæ–°æ•°æ®ï¼‰ç”Ÿæˆembeddingã€‚
    *** å·²æ›´æ–°ï¼Œä»¥åŒ¹é… v3 ç¦»çº¿è„šæœ¬çš„é€»è¾‘ ***
    """
    if not RUNTIME_EMBED_MODEL or not RUNTIME_EMBED_TOKENIZER:
        logging.info("âŒ è¿è¡Œæ—¶Embeddingæ¨¡å‹æœªåŠ è½½ã€‚")
        return None
    props_copy = data_item.copy()
    material_name = props_copy.pop("name", "æœªçŸ¥ç‰Œå·") 
    props_copy.pop("id", None)     
    props_copy.pop("æ¥æº", None)   
    props_copy.pop("data", None)   
    props_str = ", ".join([f"{k}: {v}" for k, v in props_copy.items() if v is not None])

    text = f"{material_name}, ææ–™å±æ€§: {props_str}"
    
    # ç”Ÿæˆ Embedding
    with torch.no_grad():
        inputs = RUNTIME_EMBED_TOKENIZER(text, return_tensors="pt", padding=True, truncation=True, max_length=512).to(RUNTIME_EMBED_DEVICE)
        outputs = RUNTIME_EMBED_MODEL(**inputs)
        last_hidden_state = outputs.last_hidden_state
        embedding = last_hidden_state.mean(dim=1).squeeze()
    
    return embedding.cpu().numpy()
'''
# è°ƒç”¨qwençš„embedding
def get_embedding_for_data(data_item):
    """
    (è¾…åŠ©å‡½æ•°)
    ä¸ºä¼ å…¥çš„å•ä¸ªææ–™æ•°æ®ï¼ˆæ–°æ•°æ®ï¼‰ç”Ÿæˆembeddingã€‚
    *** å·²æ›´æ–°ä¸ºä½¿ç”¨ DashScope API ***
    """
    
    # æ£€æŸ¥å…¨å±€ client æ˜¯å¦å·²åˆå§‹åŒ–
    if client is None:
        logging.error("âŒ è¿è¡Œæ—¶ Embedding å¤±è´¥ï¼šAPI å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ã€‚")
        return None

    # --- æ ¼å¼åŒ–æ–‡æœ¬ (é€»è¾‘ä¸ä½ ä¹‹å‰ä¸€è‡´) ---
    props_copy = data_item.copy()
    material_name = props_copy.pop("name", "æœªçŸ¥ç‰Œå·") 
    props_copy.pop("id", None)      
    props_copy.pop("æ¥æº", None)  
    props_copy.pop("data", None)    
    
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¿ç•™ identityï¼Œå› ä¸ºå®ƒå¯èƒ½æ˜¯ç”¨äº embedding çš„æœ‰æ•ˆå±æ€§
    # å¦‚æœä½ ä¸æƒ³è®© identity å‚ä¸ embeddingï¼Œåœ¨è¿™é‡Œä¹Ÿ pop æ‰å®ƒï¼š
    props_copy.pop("identity", None) 
    
    props_str = ", ".join([f"{k}: {v}" for k, v in props_copy.items() if v is not None])
    
    # ç¡®ä¿è¿™ä¸ªæ ¼å¼ä¸ä½ çš„ç¦»çº¿ API è„šæœ¬ (generate_embeddings_from_api.py) å®Œå…¨ä¸€è‡´
    text = f"{material_name}, ææ–™å±æ€§: {props_str}"
    
    # --- è°ƒç”¨ API ç”Ÿæˆ Embedding ---
    try:
        completion = client.embeddings.create(
            model="text-embedding-v4", # ä½¿ç”¨ä¸ç¦»çº¿è„šæœ¬ç›¸åŒçš„ embedding æ¨¡å‹
            input=text
        )
        
        # æå– embedding (APIè¿”å›çš„æ˜¯ list)
        embedding_list = completion.data[0].embedding
        
        # è½¬æ¢ä¸º numpy æ•°ç»„ï¼Œä¾› recall_top5_materials ä½¿ç”¨
        return np.array(embedding_list)
        
    except Exception as e:
        logging.error(f"âŒ è¿è¡Œæ—¶ Embedding API è°ƒç”¨å¤±è´¥: {e}")
        logging.error(f"   å¤±è´¥çš„æ–‡æœ¬: {text}")
        return None

def recall_top5_materials(current_node_id, data_item):
    """
    (å·¥å…·å‡½æ•°å®ç°)
    åœ¨å½“å‰èŠ‚ç‚¹ä¸‹ï¼Œæ ¹æ®ææ–™æ•°æ®ï¼Œé€šè¿‡å‘é‡å¬å›Top-5æœ€ç›¸ä¼¼çš„MaterialèŠ‚ç‚¹ã€‚
    current_node_id: å½“å‰èŠ‚ç‚¹ID
    data_item: å®Œæ•´çš„ææ–™æ•°æ® (ç”¨äºç”Ÿæˆembedding)
    """
    # if MATERIAL_EMBEDDINGS is None or not MATERIAL_METADATA or RUNTIME_EMBED_MODEL is None:
    #    return "å‘é‡å¬å›åŠŸèƒ½ä¸å¯ç”¨ï¼ˆæ¨¡å‹æˆ–å‘é‡åº“æœªåŠ è½½ï¼‰ã€‚è¯·ä½¿ç”¨ get_include_outbound æˆ– get_isbelongto_inboundã€‚"
    if MATERIAL_EMBEDDINGS is None or not MATERIAL_METADATA:
        return "å‘é‡å¬å›åŠŸèƒ½ä¸å¯ç”¨ï¼ˆé¢„è®¡ç®—çš„å‘é‡åº“æœªåŠ è½½ï¼‰ã€‚è¯·ä½¿ç”¨ get_include_outbound æˆ– get_isbelongto_inboundã€‚"
    # 1. ä¸ºæ–°æ•°æ®ç”Ÿæˆå‘é‡
    try:
        query_embedding = get_embedding_for_data(data_item)
        if query_embedding is None:
            return "ä¸ºæ–°æ•°æ®ç”Ÿæˆå‘é‡å¤±è´¥ã€‚è¯·ä½¿ç”¨å…¶ä»–å·¥å…·ã€‚"
    except Exception as e:
        logging.info(f"âŒ ä¸ºæ–°æ•°æ®ç”Ÿæˆå‘é‡æ—¶å‡ºé”™: {e}")
        return f"ä¸ºæ–°æ•°æ®ç”Ÿæˆå‘é‡æ—¶å‡ºé”™: {e}ã€‚è¯·ä½¿ç”¨å…¶ä»–å·¥å…·ã€‚"

    # 2. è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    query_embedding = query_embedding.flatten()
    query_norm = norm(query_embedding)
    if query_norm == 0:
        logging.info("âš ï¸ è­¦å‘Š: æŸ¥è¯¢å‘é‡çš„èŒƒæ•°ä¸º0ã€‚")
        return "æŸ¥è¯¢å‘é‡ç”Ÿæˆå¤±è´¥ï¼ˆèŒƒæ•°ä¸º0ï¼‰ã€‚è¯·ä½¿ç”¨å…¶ä»–å·¥å…·ã€‚"
        
    db_norms = norm(MATERIAL_EMBEDDINGS, axis=1)
    db_norms[db_norms == 0] = 1e-6 
    
    similarities = np.dot(MATERIAL_EMBEDDINGS, query_embedding) / (db_norms * query_norm)
    
    # 3. è·å–Top-5çš„ç´¢å¼•
    top_5_indices = np.argsort(similarities)[-5:][::-1]
    
    # 4. æ ¼å¼åŒ–ç»“æœ
    result_list = []
    for i, idx in enumerate(top_5_indices):
        if idx < len(MATERIAL_METADATA):
            meta_item = MATERIAL_METADATA[idx] 
            sim_score = similarities[idx]
            
            node_id = meta_item.get("identity")
            node_name = meta_item.get("name")
            node_label = meta_item.get("label")
            
            info = f"- é€‰é¡¹{chr(ord('A')+i)} (ç›¸ä¼¼åº¦: {sim_score:.4f}): {node_name}, idä¸º{node_id}, èŠ‚ç‚¹å±æ€§ä¸º{node_label}"
            info += " (è¯¥èŠ‚ç‚¹ä¸ºå‘é‡å¬å›ç»“æœ)"
            
            result_list.append(info)

    if not result_list:
        return "å‘é‡å¬å›æœªæ‰¾åˆ°ä»»ä½•ç»“æœã€‚è¯·ä½¿ç”¨å…¶ä»–å·¥å…·ã€‚"
        
    return "\n".join(result_list)

def mount_data(id, data, f_out):
    """
    (æ¨¡æ‹ŸæŒ‚è½½) å°†ç»“æœå†™å…¥æ–‡ä»¶ï¼Œè€Œä¸æ˜¯æ•°æ®åº“ã€‚
    id: ç›®æ ‡èŠ‚ç‚¹ID (æ¥è‡ª func_args["id"])
    data: å®Œæ•´çš„ææ–™æ•°æ® (åŒ…å« _id)
    f_out: æ‰“å¼€çš„æ–‡ä»¶å¥æŸ„
    """
    try:
        # data_id = data.get('_id', 'UNKNOWN_ID') # åŸä»£ç 
        data_id = data.get('identity', 'UNKNOWN_ID')  # æµ‹è¯•ç”¨
        target_node_id = id
        relation_name = "isBelongTo"

        result_record = {
            "data_id": data_id,
            "target_node_id": target_node_id,
            "relation_type": relation_name
        }

        f_out.write(json.dumps(result_record, ensure_ascii=False) + '\n')
        
        return f"æˆåŠŸè®°å½•åˆ°æ–‡ä»¶ï¼šdata {data_id} -> [{relation_name}] -> node {target_node_id}"

    except Exception as e:
        logging.info(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥: {e}")
        return f"å†™å…¥æ–‡ä»¶å¤±è´¥ï¼š{e}"

os.makedirs(RESULT_DIR, exist_ok=True)
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
result_filename = f"{RESULT_FILE_PREFIX}_{timestamp}.jsonl" 
result_filepath = os.path.join(RESULT_DIR, result_filename)

logging.info(f"âœ… ç»“æœå°†ä¿å­˜åˆ°: {result_filepath}")
# è·å–æ‰€æœ‰function
tools = []
with open('/home/thl/2025Fall/LLM_Mount_KG/tools.json', 'r', encoding='utf-8') as f:
    tools = json.load(f)

# LLMè°ƒç”¨æ¥å£
'''
client = OpenAI(
    api_key=DEEPSEEK_API_KEY, #å·²è„±æ•
    base_url=DEEPSEEK_BASE_URL,
)

client = Ark(
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    api_key=os.environ.get("ARK_API_KEY"),
)
'''

def get_supplementary_info_from_llm(client, data_item):
    """
    (æ–°å¢å‡½æ•°)
    è°ƒç”¨LLMï¼ˆç«å±±ï¼‰è·å–ææ–™çš„è¡¥å……æ‘˜è¦ä¿¡æ¯ã€‚
    """
    try:
        # æå–nameå’Œæˆåˆ†
        material_name = data_item.get("name", "æœªçŸ¥")
        composition = data_item.get("æˆåˆ†", "æœªçŸ¥")

        # å¦‚æœå…³é”®ä¿¡æ¯ç¼ºå¤±ï¼Œåˆ™ä¸è°ƒç”¨
        if material_name == "æœªçŸ¥" and composition == "æœªçŸ¥":
            logging.info("--- è¡¥å……ä¿¡æ¯ï¼šnameå’Œæˆåˆ†å‡æœªçŸ¥ï¼Œè·³è¿‡LLMè°ƒç”¨ ---")
            return "N/A"
            
        # æ„å»ºç±»ä¼¼å›¾ç‰‡ä¸­çš„æç¤º
        prompt_content = f"""
1. è¯·è¯†åˆ«ææ–™çš„æˆåˆ†ã€‚
2. åˆ†æå„æˆåˆ†çš„æ€§è´¨ã€‚
3. åŸºäºææ–™å„æˆåˆ†çš„æ€§è´¨ç†è§£è¿™å¯èƒ½æ˜¯ä»€ä¹ˆæ ·çš„ææ–™ã€‚

name: '{material_name}'
æˆåˆ†: '{composition}'

è¯·ç”¨100å­—ä»¥å†…å‘Šè¯‰æˆ‘è¿™æ˜¯ä»€ä¹ˆå…·ä½“çš„ææ–™ç±»å‹ï¼ŒåŒ…æ‹¬ç®€å•çš„åˆ¤æ–­åŸå› ã€‚
"""
        
        logging.info(f"--- æ­£åœ¨è°ƒç”¨LLMè·å–è¡¥å……ä¿¡æ¯ (Name: {material_name})... ---")
        
        response = client.chat.completions.create(
            # model="ep-20251027162913-hvhdm",  # ä½¿ç”¨ä¸ä¸»å¾ªç¯ç›¸åŒçš„æ¨¡å‹
            model="qwen3-max",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªææ–™ç§‘å­¦ä¸“å®¶ï¼Œè¯·ç®€æ˜æ‰¼è¦åœ°åˆ†æææ–™ã€‚"},
                {"role": "user", "content": prompt_content}
            ],
            # æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦ tools
        )
        
        summary = response.choices[0].message.content
        logging.info(f"--- æˆåŠŸè·å–è¡¥å……ä¿¡æ¯: {summary} ---")
        return summary

    except Exception as e:
        logging.warning(f"âš ï¸ è°ƒç”¨LLMè·å–è¡¥å……ä¿¡æ¯å¤±è´¥: {e}")
        return "è·å–è¡¥å……ä¿¡æ¯å¤±è´¥"
    
with open(result_filepath, 'w', encoding='utf-8') as f_out:
    # with open(DATA_FILE_PATH, "r") as f:  # åŸä»£ç 
    with open("/home/thl/2025Fall/LLM_Mount_KG/test/data/test.json", "r") as f: # æµ‹è¯•ç”¨
        data_list = json.load(f)
        test_data_list = data_list
        logging.info(f"--- æˆåŠŸåŠ è½½æ•°æ®ï¼Œå°†ä»…æµ‹è¯•å‰ {len(test_data_list)} æ¡æ•°æ® ---")
        for data in test_data_list:
            supplementary_info = get_supplementary_info_from_llm(client, data)
            #åˆå§‹èŠ‚ç‚¹
            curr_node = "ææ–™"
            curr_id = 0
            curr_label = "Class"
            extra_info = ""
            mount_succeeded = False

            for i in range(7):
                # æœ€å¤š6è½®
                logging.info("="*20 + f"ç¬¬{str(i+1)}è½®" + "="*20)
                prompt = f"""
# ä»»åŠ¡è¯´æ˜
ä½ æ­£åœ¨ææ–™çŸ¥è¯†å›¾è°±ä¸­å¯¼èˆªï¼Œç›®æ ‡æ˜¯å°†ææ–™æ•°æ®æŒ‚è½½åˆ°æ­£ç¡®ææ–™ç‰Œå·ä¸‹ã€‚

# å½“å‰çŠ¶æ€
- å½“å‰èŠ‚ç‚¹ID: {curr_id}ï¼Œåç§°ï¼š{curr_node}ï¼Œæ ‡ç­¾ï¼š{curr_label}
- ææ–™æ•°æ®ï¼š{str(data)}
- **è¡¥å……ä¿¡æ¯**: {supplementary_info}

# å¯ç”¨å·¥å…·
1. get_include_outbound - æŸ¥çœ‹å½“å‰èŠ‚ç‚¹çš„ä¸‹çº§åˆ†ç±»
2. get_isbelongto_inbound - æŸ¥çœ‹å½“å‰èŠ‚ç‚¹çš„åŒ…å«çš„ææ–™materialç§ç±»
3. recall_top5_materials - (å‘é‡å¬å›) å½“ get_isbelongto_inbound ç»“æœè¿‡å¤šæ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è°ƒç”¨æ­¤å·¥å…·ã€‚
4. mount_data - æŒ‚è½½ææ–™æ•°æ®

# å¯¼èˆªè§„åˆ™
1.  **å¦‚æœå½“å‰èŠ‚ç‚¹æ ‡ç­¾æ˜¯ "Material"**: 
    - **å¿…é¡»** è°ƒç”¨ `mount_data`ã€‚
2.  **å¦‚æœå½“å‰èŠ‚ç‚¹æ ‡ç­¾æ˜¯ "Class"**:
    - **å¿…é¡»** ä¼˜å…ˆè°ƒç”¨ `get_include_outbound` å¯»æ‰¾ä¸‹çº§åˆ†ç±»ã€‚
    - **(ä»…å½“ get_include_outbound è¿”å›ä¸ºç©ºæ—¶)**: ä½ æ‰åº”è¯¥è°ƒç”¨ `get_isbelongto_inbound` å¯»æ‰¾æŒ‚è½½çš„ææ–™å®ä¾‹ã€‚
{extra_info}
"""
    # todo promptè¿™é‡Œå› ä¸ºæš‚æ—¶å‘é‡å¬å›æœªå®ç°ï¼Œè¦æ±‚å…¶åˆ°MaterialèŠ‚ç‚¹å¼ºè¡Œæ‰§è¡ŒæŒ‚è½½
                logging.info(prompt)
                # ç”¨æˆ·æŸ¥è¯¢
                messages = [{"role": "user", "content": prompt}]

                # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šæ¨¡å‹å†³å®šæ˜¯å¦è°ƒç”¨å‡½æ•°
                response = client.chat.completions.create(
                    # model="deepseek-chat",
                    # model="ep-20251027162913-hvhdm",
                    model="qwen3-max",
                    messages=messages,
                    tools=tools,
                    tool_choice="auto"
                )

                response_message = response.choices[0].message

                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¦æ±‚è°ƒç”¨å‡½æ•°
                if response_message.tool_calls:
                    logging.info("-"*30)
                    logging.info("function call")
                    # æå–å‡½æ•°è°ƒç”¨ä¿¡æ¯
                    tool_call = response_message.tool_calls[0]
                    func_name = tool_call.function.name
                    func_args = json.loads(tool_call.function.arguments)

                    logging.info(f"function name: {func_name}")
                    logging.info(f"function args: {func_args}")
                    logging.info("-"*30)
                    
                    # æ‰§è¡Œå¯¹åº”çš„å‡½æ•°
                    if func_name == "get_include_outbound":
                        tool_result = get_include_outbound(func_args["id"])
                        if len(tool_result) == 0:
                            extra_info = "ä¸Šä¸€æ¬¡è°ƒç”¨get_include_outboundæ²¡æœ‰ä»»ä½•ç»“æœï¼Œåº”è¯¥ä½¿ç”¨å…¶ä»–å·¥å…·å‡½æ•°ã€‚"
                            continue

                    elif func_name == "get_isbelongto_inbound":
                        # 1. å…ˆè·å– *æ‰€æœ‰* åŸå§‹æ•°æ®
                        inbound_ids, inbound_names, inbound_labels = neo4j.get_inbound_by_id(func_args["id"], "isBelongTo")
                        
                        total_count = len(inbound_ids)
                        
                        if total_count > 5:
                            # 2. æ•°é‡è¿‡å¤šï¼Œè‡ªåŠ¨è§¦å‘å‘é‡å¬å›
                            logging.info(f"--- èŠ‚ç‚¹ {curr_id} å®ä¾‹è¿‡å¤š ({total_count}ä¸ª)ï¼Œè‡ªåŠ¨è§¦å‘å‘é‡å¬å› ---")
                            tool_result = recall_top5_materials(func_args["id"], data)
                            if not tool_result or "ä¸å¯ç”¨" in tool_result or "æœªæ‰¾åˆ°" in tool_result or "å¤±è´¥" in tool_result:
                                logging.info(f"âŒ å‘é‡å¬å›å¤±è´¥: {tool_result}")
                                extra_info = "å‘é‡å¬å›å¤±è´¥ï¼Œç»ˆæ­¢å½“å‰æ•°æ®ã€‚"
                                break # ç»ˆæ­¢å½“å‰æ•°æ®çš„å¤„ç†
                        
                        elif 0 < total_count <= 5:
                            # 3. æ•°é‡å¯æ§ (<=5)ï¼Œè°ƒç”¨ *æ–°* çš„æ ¼å¼åŒ–å‡½æ•°
                            logging.info(f"--- èŠ‚ç‚¹ {curr_id} å®ä¾‹æ•°é‡å¯æ§ ({total_count}ä¸ª)ï¼Œä½¿ç”¨ get_isbelongto_inbound ---")
                            # æˆ‘ä»¬é‡ç”¨å·²ç»è·å–çš„æ•°æ®ï¼Œè€Œä¸æ˜¯å†æ¬¡æŸ¥è¯¢
                            tool_result = get_isbelongto_inbound(inbound_ids, inbound_names, inbound_labels)
                        
                        else: # total_count == 0
                            # 4. æ²¡æœ‰ä»»ä½•å®ä¾‹
                            tool_result = "" # å°†è§¦å‘ä¸‹é¢çš„ len(tool_result) == 0
                        
                        if len(tool_result) == 0:
                            extra_info = "ä¸Šä¸€æ¬¡è°ƒç”¨get_isbelongto_inboundæ²¡æœ‰ä»»ä½•ç»“æœã€‚è¿™å¯èƒ½æ˜¯ä¸€ä¸ªç©ºçš„å¶å­èŠ‚ç‚¹ï¼Œæ— æ³•æŒ‚è½½ã€‚"
                            logging.info(extra_info)
                            break # ç»ˆæ­¢å½“å‰æ•°æ®çš„å¤„ç†
                        # <--- æ–°é€»è¾‘ç»“æŸ ---

                    elif func_name == "recall_top5_materials":
                        # LLM ä»ç„¶å¯èƒ½ç›´æ¥è°ƒç”¨å®ƒ (ä¾‹å¦‚åœ¨promptTuningå¤±è´¥æ—¶)ï¼Œæˆ‘ä»¬ä¿ç•™è¿™ä¸ªè·¯å¾„
                        logging.info("--- LLM ä¸»åŠ¨è°ƒç”¨ recall_top5_materials ---")
                        tool_result = recall_top5_materials(func_args["id"], data)
                        if not tool_result or "ä¸å¯ç”¨" in tool_result or "æœªæ‰¾åˆ°" in tool_result or "å¤±è´¥" in tool_result:
                            logging.info(f"âŒ å‘é‡å¬å›å¤±è´¥: {tool_result}")
                            extra_info = "å‘é‡å¬å›å¤±è´¥ï¼Œç»ˆæ­¢å½“å‰æ•°æ®ã€‚"
                            break
                        
                    elif func_name == "mount_data":
                        tool_result = mount_data(func_args["id"], data, f_out)
                        logging.info(tool_result)
                        mount_succeeded = True
                        break

                    extra_info = ""                     
                    prompt = f"""
# ä»»åŠ¡è¯´æ˜
ä½ æ­£åœ¨ææ–™çŸ¥è¯†å›¾Pä¸­å¯¼èˆªï¼Œä½ éœ€è¦æŠ‰æ‹©å½“å‰èŠ‚ç‚¹çš„èµ°å‘ã€‚

# å½“å‰çŠ¶æ€
- å½“å‰èŠ‚ç‚¹ID: {curr_id}ï¼Œåç§°ï¼š{curr_node}ï¼Œæ ‡ç­¾ï¼š{curr_label}
- ææ–™æ•°æ®ï¼š{str(data)}
- **è¡¥å……ä¿¡æ¯**: {supplementary_info}

# èŠ‚ç‚¹å»å‘
{tool_result}

è¯·æ ¹æ®èŠ‚ç‚¹å»å‘ä¿¡æ¯ï¼ˆåŒ…æ‹¬åç§°å’Œä¸‹æ¸¸èŠ‚ç‚¹ç›¸å…³ä¾‹å­ï¼‰ï¼Œé€‰æ‹©ä¸€ä¸ªä¸å½“å‰ææ–™æ•°æ®æœ€æ¥è¿‘çš„ç±»å‹çš„ææ–™å»å‘è¾“å‡ºã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºIDï¼Œåç§°ï¼Œæ ‡ç­¾ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–æ–‡å­—ï¼š
[èŠ‚ç‚¹ID] [èŠ‚ç‚¹åç§°] [èŠ‚ç‚¹æ ‡ç­¾]

ç¤ºä¾‹ï¼š
0 ææ–™ Class
"""
                    logging.info(prompt)
                    messages = [{"role": "user", "content": prompt}]
                    
                    # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šæ¨¡å‹åŸºäºå‡½æ•°ç»“æœå†³å®šå»å‘
                    second_response = client.chat.completions.create(
                        # model="deepseek-chat",
                        # model="ep-20251027162913-hvhdm",
                        model="qwen3-max",
                        messages=messages
                    )
                    final_answer = second_response.choices[0].message.content
                    logging.info("-"*30)
                    logging.info(final_answer)
                    logging.info("-"*30)
                    if final_answer == "å®Œæ¯•":
                        break
                    else:
                        try:
                            # <--- ä¿®å¤ï¼šé‡å†™è§£æå™¨ä»¥å¤„ç†å¸¦ç©ºæ ¼çš„åç§° ---
                            clean_answer = final_answer.replace('[', '').replace(']', '').strip()
                            parts = clean_answer.split()
                            
                            if len(parts) >= 3:
                                curr_id = parts[0]
                                # æ ‡ç­¾å§‹ç»ˆæ˜¯æœ€åä¸€ä¸ªè¯
                                curr_label = parts[-1]
                                # åç§°æ˜¯ ID å’Œ Label ä¹‹é—´çš„æ‰€æœ‰å†…å®¹
                                curr_node = " ".join(parts[1:-1])
                            else:
                                # è‡³å°‘éœ€è¦ ID, Name, Label
                                logging.info(f"âŒ AIè¿”å›æ ¼å¼é”™è¯¯ (éƒ¨ä»¶å¤ªå°‘): '{final_answer}'")
                                raise IndexError
                            
                        except IndexError:
                            logging.info(f"âŒ AIè¿”å›æ ¼å¼é”™è¯¯: '{final_answer}'ï¼Œ ç»ˆæ­¢å½“å‰æ•°æ®å¤„ç†ã€‚")
                            break
                        
                else:
                    # æ¨¡å‹æœªè°ƒç”¨å‡½æ•°ï¼Œç›´æ¥è¿”å›å›ç­”
                    logging.info(response_message.content)

            # æ£€æŸ¥æŒ‚è½½æ˜¯å¦æˆåŠŸï¼Œå¦‚æœä¸æˆåŠŸï¼Œåˆ™å†™å…¥å¤±è´¥è®°å½•
            if not mount_succeeded:
                try:
                    # ä» data å¯¹è±¡è·å– identity
                    data_id = data.get('identity', 'UNKNOWN_ID') 
                    logging.info(f"--- æ•°æ® {data_id} æœªèƒ½æˆåŠŸæŒ‚è½½ï¼Œå†™å…¥ç©ºå€¼è®°å½• ---")

                    failure_record = {
                        "data_id": data_id,
                        "target_node_id": None,  # æŒ‰è¦æ±‚è®¾ä¸ºç©ºå€¼
                        "relation_type": None    # æŒ‰è¦æ±‚è®¾ä¸ºç©ºå€¼
                    }
                    f_out.write(json.dumps(failure_record, ensure_ascii=False) + '\n')

                except Exception as e:
                    logging.info(f"âŒ å†™å…¥å¤±è´¥è®°å½• (data_id: {data_id}) æ—¶å‘ç”Ÿé”™è¯¯: {e}")
logging.info(f"âœ… ä»»åŠ¡å®Œæˆï¼Œæ‰€æœ‰æ•°æ®å·²å¤„ç†å¹¶ä¿å­˜åˆ°: {result_filepath}")